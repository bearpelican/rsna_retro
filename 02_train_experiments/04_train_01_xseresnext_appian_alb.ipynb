{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading imports\n"
     ]
    }
   ],
   "source": [
    "from rsna_retro.imports import *\n",
    "from rsna_retro.metadata import *\n",
    "from rsna_retro.preprocess import *\n",
    "from rsna_retro.train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '04_xse_resnext_512_appian_alb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pretrainedmodels.se_resnext50_32x4d(num_classes=6, pretrained=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.avg_pool = nn.AdaptiveAvgPool2d(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state['model'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sp2 = '~/kaggle/rsna_retro/models/model100/fold0_ep2.pt'\n",
    "sp3 = '~/kaggle/rsna_retro/models/model100/fold0_ep3.pt'\n",
    "\n",
    "saved_path = Path(sp3).expanduser()\n",
    "state = torch.load(saved_path, map_location='cpu')\n",
    "m.load_state_dict(state['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = get_album_data(64, 384, splits=Meta.splits_stg1, img_dir=path_jpg)\n",
    "learn = get_learner(dls, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy_multi</th>\n",
       "      <th>accuracy_any</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.071588</td>\n",
       "      <td>0.079748</td>\n",
       "      <td>0.975101</td>\n",
       "      <td>0.951047</td>\n",
       "      <td>1:53:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy_multi</th>\n",
       "      <th>accuracy_any</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.072019</td>\n",
       "      <td>0.076472</td>\n",
       "      <td>0.976439</td>\n",
       "      <td>0.953352</td>\n",
       "      <td>1:53:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.063119</td>\n",
       "      <td>0.071228</td>\n",
       "      <td>0.977949</td>\n",
       "      <td>0.956904</td>\n",
       "      <td>1:54:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.056388</td>\n",
       "      <td>0.069510</td>\n",
       "      <td>0.978690</td>\n",
       "      <td>0.958304</td>\n",
       "      <td>1:53:33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "do_fit(learn, 3, 5e-4, freeze=True)\n",
    "learn.save(f'runs/{name}-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(f'runs/{name}-1')\n",
    "sub_fn = f'subm/{name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.dls = get_test_data(Meta.df_tst, bs=128, sz=384, tst_dir='tst_jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ob = learn.dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds,targs = learn.get_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_csv = submission(Meta.df_tst, preds, fn=sub_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26.0M/26.0M [00:02<00:00, 11.9MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Successfully submitted to RSNA Intracranial Hemorrhage Detection"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.competition_submit(f'{sub_fn}.csv', f'{name} 384 384 384 appian se_resnext50', 'rsna-intracranial-hemorrhage-detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ref': 14453417,\n",
       " 'totalBytes': 27277209,\n",
       " 'date': '2020-02-11T18:51:32.45Z',\n",
       " 'description': '04_xse_resnext_512_appian_alb 384 384 384 appian se_resnext50',\n",
       " 'errorDescription': None,\n",
       " 'fileName': '04_xse_resnext_512_appian_alb.csv',\n",
       " 'publicScore': None,\n",
       " 'privateScore': None,\n",
       " 'status': 'pending',\n",
       " 'submittedBy': 'Andrew Shaw',\n",
       " 'submittedByRef': 'bearpelican',\n",
       " 'teamName': 'Andrew Shaw',\n",
       " 'type': 'standard',\n",
       " 'url': 'https://www.kaggle.com/submissions/14453417/14453417.raw'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.competitions_submissions_list('rsna-intracranial-hemorrhage-detection')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_appfeat512 = path/'appian_features_384_album'\n",
    "path_appfeat512_tst = path/'appian_tst_features_384_album'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_save = f'runs/{name}-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dls = get_test_data(Meta.df_tst, bs=256, sz=None, tst_dir='tst_jpg')\n",
    "learn.dls = get_test_data(Meta.df_tst, bs=128, sz=384, tst_dir='tst_jpg')\n",
    "learn.load(fn_save)\n",
    "learn.model.last_linear = nn.Identity()\n",
    "save_features(learn, path_appfeat512_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_pth = path_appfeat512_tst.ls()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='752802' class='' max='752802', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [752802/752802 05:02<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.dls = get_test_data(Meta.df_comb, bs=128, sz=None, tst_dir='nocrop_jpg')\n",
    "save_features(learn, path_appfeat512)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
