{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp contrastive_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading imports\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "from rsna_retro.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss \n",
    "\n",
    "### Taken from here: https://github.com/adambielski/siamese-triplet/blob/master/losses.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TripletLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Triplet loss\n",
    "    Takes embeddings of an anchor sample, a positive sample and a negative sample\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin=0.5):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, anchor, positive, negative=None, size_average=True):\n",
    "        if negative is None: negative = positive.flip(dims=[0])\n",
    "        distance_positive = (anchor - positive).pow(2).sum(1)  # .pow(.5)\n",
    "        distance_negative = (anchor - negative).pow(2).sum(1)  # .pow(.5)\n",
    "        losses = F.relu(distance_positive - distance_negative + self.margin)\n",
    "        return losses.mean() if size_average else losses.sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checking Triple loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tloss = TripletLoss(margin=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(24.8184))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anch = torch.randn(4, 8) # bs x features\n",
    "pos = anch + 0.1 # bs x feat\n",
    "neg = pos.flip(dims=[0])\n",
    "tloss(anch,pos,neg), tloss(anch,neg,pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tloss(anch,pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check Contrastive Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# https://github.com/adambielski/siamese-triplet/blob/master/losses.py\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Contrastive loss\n",
    "    Takes embeddings of two samples and a target label == 1 if samples are from the same class and label == 0 otherwise\n",
    "    \"\"\"\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.eps = 1e-9\n",
    "\n",
    "    def forward(self, output1, output2, target, size_average=True):\n",
    "        distances = (output2 - output1).pow(2).sum(-1)  # squared distances\n",
    "#         distances = F.pairwise_distance(output1, output2, keepdim=True).pow(2).sum(-1)  # squared distances\n",
    "        losses = (target.float() * distances +\n",
    "                        (1 + -1 * target).float() * F.relu(self.margin - (distances + self.eps).sqrt()).pow(2))\n",
    "        return losses.mean() if size_average else losses.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original code\n",
    "# https://github.com/harveyslash/Facial-Similarity-with-Siamese-Networks-in-Pytorch/blob/master/Siamese-networks-medium.ipynb\n",
    "class PairContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2, keepdim = False)\n",
    "        if len(euclidean_distance.shape)>1: euclidean_distance = euclidean_distance.sum(-1)\n",
    "        c_pos = (label) * torch.pow(euclidean_distance, 2)\n",
    "        c_neg = (1-label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)\n",
    "        loss_contrastive = (c_neg + c_pos)\n",
    "        return loss_contrastive.mean()\n",
    "\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# https://stackoverflow.com/questions/47107589/how-do-i-use-a-bytetensor-in-a-contrastive-cosine-loss-function\n",
    "class CosineContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        cos_sim = F.cosine_similarity(output1, output2, dim=-1)\n",
    "        loss_cos_con = torch.mean((label) * torch.div(torch.pow((1.0-cos_sim), 2), 4) +\n",
    "                                    (1-label) * torch.pow(cos_sim * torch.lt(cos_sim, self.margin), 2))\n",
    "        return loss_cos_con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(output1, output2):\n",
    "    num = output1.T @ output2\n",
    "    denom = torch.norm(output1) * torch.norm(output2)\n",
    "    out = num / denom\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = {\n",
    "    '1_contloss': ContrastiveLoss(),\n",
    "    '2_pairloss': PairContrastiveLoss(),\n",
    "    '3_cosloss': CosineContrastiveLoss(),\n",
    "#     '4_xentloss': XentContrastiveLoss()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_out(t,a,l):\n",
    "    return {k:v(t,a,l) for k,v in ls.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 8]), torch.Size([4, 8]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targ = torch.randn(4, 8) # bs x features\n",
    "aug = targ + 0.1 # bs x feat\n",
    "targ.shape, aug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1_contloss': tensor(0.0200),\n",
       " '2_pairloss': tensor(0.0200),\n",
       " '3_cosloss': tensor(0.0243)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.zeros(aug.shape[0])\n",
    "labels[0] = 1\n",
    "\n",
    "# single target to rest of batch\n",
    "loss_out(targ[:1], aug, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1_contloss': tensor(0.0800),\n",
       " '2_pairloss': tensor(0.0800),\n",
       " '3_cosloss': tensor(4.0329e-06)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1-to-1 match targ -> aug. Loss should be 8x higher\n",
    "labels = torch.ones(aug.shape[0])\n",
    "loss_out(targ, aug, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1_contloss': tensor(18.8922),\n",
       " '2_pairloss': tensor(18.8921),\n",
       " '3_cosloss': tensor(0.2493)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# single targ -> all rand. Super High Loss\n",
    "labels = torch.ones(aug.shape[0])\n",
    "loss_out(targ[:1], aug, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batched contrastive loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def batched_labels(output1, output2, onehot=True):\n",
    "    bs = output1.shape[0]\n",
    "    rp = [1]*len(output1.shape)\n",
    "    o1 = output1.repeat(*rp,bs).view(bs,*output1.shape)\n",
    "    labels = torch.arange(bs, device=output1.device)\n",
    "    if onehot: labels = torch.eye(o1.shape[0], device=output1.device)[labels]\n",
    "    return o1, output2, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "closs = ContrastiveLoss()\n",
    "# closs = CosineContrastiveLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs,feat=6,18 # \n",
    "targ = torch.randn(bs, feat)*5 # bs x features\n",
    "aug = targ+0.1 # bs x features\n",
    "# aug = torch.randn(bs, feat) # bs x features\n",
    "o1, o2, l = batched_labels(targ, targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 6, 18])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o1.pow(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 6, 18])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(135.7687)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(o1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 6, 18]), torch.Size([6, 18]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o1.shape, o2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0007)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs = F.cosine_similarity(o1, o2, dim=-1)/0.1\n",
    "F.cross_entropy(cs, torch.arange(bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7311, 0.2689],\n",
       "        [0.2689, 0.7311]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(torch.eye(2), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3133)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(torch.eye(2), torch.tensor([0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 20.0000,   4.6216,  -3.3481,   4.0333,  -2.9250,   2.5821],\n",
       "        [  4.6216,  20.0000,   0.6266,   0.6842,   2.6846,  -2.2457],\n",
       "        [ -3.3481,   0.6266,  20.0000, -10.0835,  -2.5101,   2.1343],\n",
       "        [  4.0333,   0.6842, -10.0835,  20.0000,  -7.1823,  -4.2012],\n",
       "        [ -2.9250,   2.6846,  -2.5101,  -7.1823,  20.0000,   5.4538],\n",
       "        [  2.5821,  -2.2457,   2.1343,  -4.2012,   5.4538,  20.0000]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs/0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 4.0384e-34, 0.0000e+00, 2.1319e-35, 0.0000e+00, 1.5048e-38],\n",
       "        [4.0384e-34, 1.0000e+00, 8.5339e-43, 1.1393e-42, 2.5118e-38, 0.0000e+00],\n",
       "        [0.0000e+00, 8.5339e-43, 1.0000e+00, 0.0000e+00, 0.0000e+00, 1.6041e-39],\n",
       "        [2.1319e-35, 1.1393e-42, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 2.5118e-38, 0.0000e+00, 0.0000e+00, 1.0000e+00, 2.5895e-32],\n",
       "        [1.5048e-38, 0.0000e+00, 1.6041e-39, 0.0000e+00, 2.5895e-32, 1.0000e+00]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(cs/0.1, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 6, 18]), torch.Size([6, 18]), torch.Size([6, 6]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o1.shape, o2.shape, l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0300)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses = []\n",
    "for i in range(targ.shape[0]):\n",
    "    bs = targ.shape[0]\n",
    "    labels = torch.zeros(bs)\n",
    "    labels[i] = 1 # set current target as the only positive label\n",
    "    losses.append(closs(targ[i], aug, labels))\n",
    "torch.stack(losses).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closs(o1,o2,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(175.1980)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity checking - setting wrong target as positive label\n",
    "losses = []\n",
    "for i in range(targ.shape[0]):\n",
    "    bs = targ.shape[0]\n",
    "    labels = torch.zeros(bs)\n",
    "    labels[0] = 1 # set current target as the only positive label\n",
    "    losses.append(closs(targ[i], aug, labels))\n",
    "torch.stack(losses).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(174.6499)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l3 = l[torch.zeros(o1.shape[0]).long()]\n",
    "closs(o1,o2,l3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(882.6721)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity checking - setting wrong target as positive label\n",
    "losses = []\n",
    "for i in range(targ.shape[0]):\n",
    "    bs = targ.shape[0]\n",
    "    labels = torch.ones(bs)\n",
    "    labels[0] = 1 # set current target as the only positive label\n",
    "    losses.append(closs(targ[i], aug, labels))\n",
    "torch.stack(losses).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(882.4920)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l4 = torch.ones(o1.shape[0], o1.shape[0])\n",
    "closs(o1,o2,l4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XentContrastiveLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# https://arxiv.org/pdf/2002.05709.pdf\n",
    "class XentOldContrastiveLoss(nn.Module):\n",
    "    def __init__(self, temp=0.5):\n",
    "        super().__init__()\n",
    "        self.temp = temp\n",
    "\n",
    "    def forward(self, output1, output2, labels):\n",
    "        cos_sim = F.cosine_similarity(output1, output2, dim=-1)/self.temp\n",
    "        xent_loss = F.cross_entropy(cos_sim,labels.long())\n",
    "        return xent_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs,feat=4,16 # \n",
    "targ = torch.randn(bs, feat) # bs x features\n",
    "rand_aug = torch.randn(bs, feat) # bs x features\n",
    "aug = targ + 0.1 # bs x feat\n",
    "output1, output2, labels = batched_labels(targ, aug, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7626)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, lmax = labels.max(dim=-1); lmax\n",
    "xent_loss = XentOldContrastiveLoss(1.0)\n",
    "xent_loss(output1, output2, lmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim = F.cosine_similarity(output1, output2, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6937, -1.8886, -1.5841, -1.9388],\n",
       "        [-1.9855, -0.7927, -1.3897, -1.8270],\n",
       "        [-1.7515, -1.4645, -0.8636, -1.7507],\n",
       "        [-1.9708, -1.7779, -1.6339, -0.7002]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsoft = F.log_softmax(cos_sim, dim=-1); lsoft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6937, -1.9863, -1.7527, -1.9423],\n",
       "        [-1.8878, -0.7927, -1.4606, -1.7327],\n",
       "        [-1.5828, -1.3936, -0.8636, -1.5856],\n",
       "        [-1.9674, -1.8721, -1.7990, -0.7002]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsoft1 = torch.log(torch.exp(cos_sim)/torch.exp(cos_sim).sum(dim=-1)); lsoft1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7626)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nll loss\n",
    "l_nll = torch.mean(torch.sum(-labels * lsoft1, dim=1)); l_nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7626)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.nll_loss(lsoft, lmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Xent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9960, -0.1988,  0.1057, -0.2491],\n",
       "        [-0.1980,  0.9948,  0.3978, -0.0395],\n",
       "        [ 0.1069,  0.3939,  0.9948,  0.1077],\n",
       "        [-0.2776, -0.0846,  0.0594,  0.9930]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.7075, 0.8197, 1.1115, 0.7795],\n",
       "        [0.8204, 2.7042, 1.4885, 0.9613],\n",
       "        [1.1128, 1.4827, 2.7041, 1.1137],\n",
       "        [0.7576, 0.9189, 1.0612, 2.6994]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cexp = torch.exp(cos_sim)\n",
    "cexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.4182, 5.9743, 6.4134, 5.4370])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cexp.sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7107, 3.2702, 3.7092, 2.7376])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_denom = (cexp*(1-labels)).sum(dim=-1); neg_denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9960, 0.9948, 0.9948, 0.9930])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = cos_sim[range(lmax.shape[0]),lmax]; pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7107, 3.2702, 3.7092, 2.7376])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cexp.sum(dim=-1) - torch.exp(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1679e-03, -1.3837e+00, -1.2052e+00, -1.2561e+00],\n",
       "        [-1.1952e+00, -1.9004e-01, -9.1303e-01, -1.0466e+00],\n",
       "        [-8.9029e-01, -7.9096e-01, -3.1605e-01, -8.9943e-01],\n",
       "        [-1.2748e+00, -1.2695e+00, -1.2515e+00, -1.4067e-02]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsoft2 = torch.log(cexp/neg_denom); lsoft2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.1635)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_nll = torch.mean(torch.sum(-lmax * lsoft2, dim=1)); l_nll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.7075, 0.8197, 1.1115, 0.7795],\n",
       "        [0.8204, 2.7042, 1.4885, 0.9613],\n",
       "        [1.1128, 1.4827, 2.7041, 1.1137],\n",
       "        [0.7576, 0.9189, 1.0612, 2.6994]])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = 1.0\n",
    "cos_sim = F.cosine_similarity(output1, output2, dim=-1)/temp\n",
    "cexp = torch.exp(cos_sim)\n",
    "cexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7075, 2.7042, 2.7041, 2.6994])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = (cexp * labels).sum(dim=-1); x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7107, 3.2702, 3.7092, 2.7376])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cexp*(1-labels)).sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7107, 3.2702, 3.7092, 2.7376])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denom = cexp.sum(dim=-1) - x; denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1679e-03, 1.3837e+00, 1.2052e+00, 1.2561e+00],\n",
       "        [1.1952e+00, 1.9004e-01, 9.1303e-01, 1.0466e+00],\n",
       "        [8.9029e-01, 7.9096e-01, 3.1605e-01, 8.9943e-01],\n",
       "        [1.2748e+00, 1.2695e+00, 1.2515e+00, 1.4067e-02]])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsoft = -torch.log(cexp/denom)\n",
    "lsoft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0012, 0.1900, 0.3160, 0.0141])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-torch.log(x)+torch.log(denom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "upper bound and larger bound inconsistent with step sign",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-215-e86d8a7147fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: upper bound and larger bound inconsistent with step sign"
     ]
    }
   ],
   "source": [
    "torch.log(torch.arange(10,1).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0012, 0.1900, 0.3160, 0.0141])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_denom = (cexp*(1-labels)).sum(dim=-1); neg_denom\n",
    "lsoft1 = torch.log(cexp/neg_denom)\n",
    "lsoft2 = torch.sum(-labels * lsoft1, dim=-1)\n",
    "lsoft2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put it into code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# https://arxiv.org/pdf/2002.05709.pdf\n",
    "class XentContrastiveLoss(nn.Module):\n",
    "    def __init__(self, temp=0.5):\n",
    "        super().__init__()\n",
    "        self.temp = temp\n",
    "\n",
    "    def forward(self, output1, output2, labels):\n",
    "        cos_sim = F.cosine_similarity(output1, output2, dim=-1)/self.temp\n",
    "        cexp = torch.exp(cos_sim)\n",
    "        neg_denom = (cexp*(1-labels)).sum(dim=-1)\n",
    "        lsoft = torch.log(cexp/neg_denom)\n",
    "        lsoft = torch.sum(-labels * lsoft, dim=-1)\n",
    "        print(lsoft)\n",
    "        return lsoft.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class XentContrastiveLoss2(nn.Module):\n",
    "    def __init__(self, temp=0.5):\n",
    "        super().__init__()\n",
    "        self.temp = temp\n",
    "\n",
    "    def forward(self, output1, output2, labels):\n",
    "        cos_sim = F.cosine_similarity(output1, output2, dim=-1)/self.temp\n",
    "        cexp = torch.exp(cos_sim)\n",
    "        x = (cexp * labels).sum(dim=-1)\n",
    "        denom = cexp.sum(dim=-1) - x\n",
    "        lsoft = -torch.log(x/denom)\n",
    "        print(lsoft)\n",
    "        return lsoft.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BatchContrastiveLoss(nn.Module):\n",
    "    def __init__(self, loss_func):\n",
    "        super().__init__()\n",
    "        self.loss_func = loss_func\n",
    "        self.onehot = not isinstance(loss_func, XentOldContrastiveLoss)\n",
    "        \n",
    "    def forward(self, output1, output2):\n",
    "        output1, output2, labels = batched_labels(output1, output2, self.onehot)\n",
    "        return self.loss_func(output1, output2, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = 0.1\n",
    "ls2 = {\n",
    "#     '1_contloss': ContrastiveLoss(margin=1.0),\n",
    "    '4_xentloss': XentContrastiveLoss(temp=temp),\n",
    "    '5_xentloss2': XentContrastiveLoss2(temp=temp),\n",
    "    '6_oldxentloss': XentOldContrastiveLoss(temp=temp)\n",
    "}\n",
    "\n",
    "def batch_loss_out(t,a):\n",
    "    return {k:BatchContrastiveLoss(v)(t,a) for k,v in ls2.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs,feat=16,128 # \n",
    "targ = torch.randn(bs, feat) # bs x features\n",
    "rand_aug = torch.randn(bs, feat) # bs x features\n",
    "aug = targ + 0.05 # bs x feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'4_xentloss': tensor(-6.8875),\n",
       " '5_xentloss2': tensor(-6.8876),\n",
       " '6_oldxentloss': tensor(0.0010)}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_loss_out(targ,targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'4_xentloss': tensor(3.4285),\n",
       " '5_xentloss2': tensor(3.4285),\n",
       " '6_oldxentloss': tensor(3.4732)}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_loss_out(targ,rand_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'4_xentloss': tensor(7.5412),\n",
       " '5_xentloss2': tensor(7.5412),\n",
       " '6_oldxentloss': tensor(7.5418)}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs,feat=256,256 # \n",
    "targ = torch.randn(bs, feat) # bs x features\n",
    "aug = targ+0.1 # bs x features\n",
    "rand_aug = torch.randn(bs, feat) # bs x features\n",
    "batch_loss_out(targ,-aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_metadata.ipynb.\n",
      "Converted 01_preprocess.ipynb.\n",
      "Converted 01_preprocess_mean_std.ipynb.\n",
      "Converted 02_train.ipynb.\n",
      "Converted 02_train_01_save_features.ipynb.\n",
      "Converted 03_train3d.ipynb.\n",
      "Converted 04_trainfull3d_deprecated.ipynb.\n",
      "Converted 04_trainfull3d_labels.ipynb.\n",
      "Converted 05_train_adjacent.ipynb.\n",
      "Converted 06_seutao_features.ipynb.\n",
      "Converted 07_adni.ipynb.\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "#\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "Converted 07_adni_01.ipynb.\n",
      "Converted 08_contrastive_loss.ipynb.\n",
      "Converted 08_imagewang.ipynb.\n",
      "Converted 08_train_self_supervised.ipynb.\n",
      "Converted 08_train_self_supervised_train_1.ipynb.\n",
      "Converted 08_train_self_supervised_train_2_nocombined.ipynb.\n",
      "Converted 08_train_self_supervised_train_2_nocombined_contrast.ipynb.\n",
      "Converted 08_train_self_supervised_train_3.ipynb.\n",
      "Converted 08_train_self_supervised_train_4_nocombined_xent-Copy1.ipynb.\n",
      "Converted 08_train_self_supervised_train_4_nocombined_xent.ipynb.\n",
      "Converted 09_ImageWang_Leadboard_128.ipynb.\n",
      "Converted 09_ImageWang_Leadboard_SS.ipynb.\n",
      "Converted 09_ImageWang_Leadboard_SS_1.ipynb.\n",
      "Converted Tabular_02_FeatureImportance.ipynb.\n",
      "Converted Untitled.ipynb.\n",
      "Converted Untitled1.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
