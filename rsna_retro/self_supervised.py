# AUTOGENERATED! DO NOT EDIT! File to edit: 08_train_self_supervised.ipynb (unless otherwise specified).

__all__ = ['TripletLoss', 'TripletCallback', 'ContrastiveLoss', 'ContrastiveCallback', 'BatchContrastiveLoss',
           'get_ss_gen', 'get_ss_data', 'get_aug_pipe', 'CombinedContrastiveCallback', 'CombinedContrastiveLoss',
           'loss_cont', 'loss_class', 'accuracy_ss', 'CombinedModel']

# Cell
from .imports import *
from .metadata import *
from .preprocess import *
from .train import *

# Cell
# Taken from this repo:
class TripletLoss(nn.Module):
    """
    Triplet loss
    Takes embeddings of an anchor sample, a positive sample and a negative sample
    """

    def __init__(self, margin):
        super(TripletLoss, self).__init__()
        self.margin = margin

    def forward(self, anchor, positive, negative, size_average=True):
        distance_positive = (anchor - positive).pow(2).sum(1)  # .pow(.5)
        distance_negative = (anchor - negative).pow(2).sum(1)  # .pow(.5)
        losses = F.relu(distance_positive - distance_negative + self.margin)
        return losses.mean() if size_average else losses.sum()


# Cell
class TripletCallback(Callback):
    def __init__(self, aug=None):
        self.aug = ifnone(aug, RandomResizedCropGPU(size=256, min_scale=0.4, ratio=(1.,1.)))

    def begin_batch(self): # fastai(v1) function = on_batch_begin
        xb, = self.learn.xb # (bs x w x h) -> (128 x 256 x 256)
        xb_aug = self.aug(xb) # (bs x w x h) -> (128 x 256 x 256)

        self.learn.xb = (torch.cat([xb, xb_aug]),) # (bs*2 x w x h) -> (256 x 256 x 256)
        self.bs = xb.shape[0]

    def after_pred(self): # fastai(v1) function = on_loss_begin
        xb_cat = self.learn.pred # (bs*2 x feat)
        xb = xb_cat[:self.bs] # (bs x feat)
        xb_aug = xb_cat[self.bs:] # (bs x feat)
        self.learn.pred = xb
        self.learn.yb = (xb_aug, xb_aug.flip(dims=[0]))


# Cell
class ContrastiveLoss(nn.Module):
    """
    Contrastive loss
    Takes embeddings of two samples and a target label == 1 if samples are from the same class and label == 0 otherwise
    """
    def __init__(self, margin):
        super(ContrastiveLoss, self).__init__()
        self.margin = margin
        self.eps = 1e-9

    def forward(self, output1, output2, target, size_average=True):
        distances = (output2 - output1).pow(2).sum(1)  # squared distances
        losses = 0.5 * (target.float() * distances +
                        (1 + -1 * target).float() * F.relu(self.margin - (distances + self.eps).sqrt()).pow(2))
        return losses.mean() if size_average else losses.sum()

# Cell
class ContrastiveCallback(Callback):
    def __init__(self, aug=None):
        self.aug = ifnone(aug, RandomResizedCropGPU(size=256, min_scale=0.4, ratio=(1.,1.)))
    def begin_batch(self): # fastai(v1) function = on_batch_begin
        xb, = self.learn.xb # (bs x w x h) -> (128 x 256 x 256)
        xb_aug = self.aug(xb) # (bs x w x h) -> (128 x 256 x 256)

        self.learn.xb = (torch.cat([xb, xb_aug]),) # (bs*2 x w x h) -> (256 x 256 x 256)
        self.bs = xb.shape[0]

    def after_pred(self): # fastai(v1) function = on_loss_begin
        xb_cat = self.learn.pred # (bs*2 x feat)
        xb = xb_cat[:self.bs] # (bs x feat)
        xb_aug = xb_cat[self.bs:] # (bs x feat)
        self.learn.pred = xb
        self.learn.yb = (xb_aug,)

# Cell
class BatchContrastiveLoss(nn.Module):
    def __init__(self, margin=0.5):
        super().__init__()
        self.loss_func = ContrastiveLoss(margin)

    def forward(self, targ, aug):
        losses = []
        for i in range(targ.shape[0]):
            bs = targ.shape[0]
            labels = torch.zeros(bs, device=targ.device)
            labels[i] = 1 # set current target as the only positive label
            losses.append(self.loss_func(targ[i], aug, labels))
        return sum(losses)

# Cell
def get_ss_gen(fns, bs, img_tfm, splits, sz=None, nw=8, test=False):
    tfms = [[img_tfm, ToTensor], [fn2label,EncodedMultiCategorize(htypes)]]
    if test: tfms = [tfms[0]]
    dsets = Datasets(fns, tfms, splits=splits)
    batch_tfms = L(IntToFloatTensor)
    if sz is not None: batch_tfms += Resize(sz)
    return dsets.dataloaders(bs=bs, num_workers=nw, after_batch=batch_tfms)

# Cell
def get_ss_data(bs, sz, splits, img_dir=path_jpg256, **kwargs):
    return get_ss_gen(L(list(Meta.df_comb.index)), bs=bs, img_tfm=get_pil_fn(path/img_dir),
                        sz=sz, splits=splits, **kwargs)

# Cell
def get_aug_pipe(size, min_scale):
    nrm = Normalize.from_stats(mean,std)
    pipe = Pipeline([nrm, RandomResizedCropGPU(size=size, min_scale=min_scale, ratio=(1.,1.)), *aug_transforms()])
    return pipe

# Cell
class CombinedContrastiveCallback(Callback):
    def __init__(self, size=256):
        self.update_size(size)

    def update_size(self, size):
        self.aug_targ = get_aug_pipe(size, min_scale=0.7)
        self.aug_pos = get_aug_pipe(size, min_scale=0.4)

    def set_split(self, split_idx):
        self.aug_targ.split_idx = split_idx
#         self.aug_pos.split_idx = split_idx # always keep augmentation

    def begin_validate(self): self.set_split(1)
    def begin_train(self): self.set_split(0)

    def begin_batch(self):
        xb, = self.learn.xb
        xb_targ = self.aug_targ(xb)
        xb_pos = self.aug_pos(xb)

        self.learn.xb = xb_targ, xb_pos


# Cell
class CombinedContrastiveLoss(nn.Module):
    def __init__(self, margin=0.5):
        super().__init__()
        self.loss_cont = BatchContrastiveLoss(margin)
        self.loss_class = get_loss()

    def forward(self, out, labels):
        targ, aug, pred = out
        loss_cont = self.loss_cont(targ, aug)
        loss_class = self.loss_class(pred, labels)

        return loss_cont + loss_class

# Cell
def loss_cont(out, labels, f):
    targ, aug, pred = out
    return f(targ, aug)

def loss_class(out, labels, f):
    targ, aug, pred = out
    return f(out[-1], labels)

# Cell
def accuracy_ss(inp, targ, thresh=0.5, sigmoid=True):
    _, _, inp = inp
    inp,targ = flatten_check(inp[:,0],targ[:,0])
    if sigmoid: inp = inp.sigmoid()
    return ((inp>thresh)==targ.bool()).float().mean()

# Cell
class CombinedModel(nn.Module):
    def __init__(self, model):
        super().__init__()
        self.model = model

    def features(self, x):
        return self.model[1][:2](self.model[0](x))

    def head(self, x):
        return self.model[1][2:](x)

    def forward(self, targ, aug):
        feat_targ = self.features(targ)
        feat_aug = self.features(aug)
        return feat_targ, feat_aug, self.head(feat_targ)

    # Forward all nn.Module methods
    def __getstate__(self): return self.model.__getstate__()
    def __setstate__(self): return self.model.__setstate__()
    def __repr__(self): return self.model.__repr__()
    def state_dict(self): return self.model.state_dict()
    def load_state_dict(self, state_dict): return self.model.load_state_dict(state_dict)

