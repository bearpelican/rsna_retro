{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp train3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading imports\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "from rsna_retro.imports import *\n",
    "from rsna_retro.metadata import *\n",
    "from rsna_retro.preprocess import *\n",
    "from rsna_retro.train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #export\n",
    "# @IntToFloatTensor\n",
    "# def encodes(self, o:TensorCTScan): return o.float().div_(self.div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class OpenCTs:\n",
    "    def __init__(self, path, open_fn=get_pil_fn, tfms=None): \n",
    "        self.fn = open_fn(path)\n",
    "        if tfms is None: tfms = [] \n",
    "        self.tfms = Pipeline(tfms+[ToTensor])\n",
    "    def __call__(self, item):\n",
    "        if isinstance(item, (str, Path)): return self.tfms(self.fn(item))\n",
    "        xs = [self.tfms(self.fn(x)) for x in item]\n",
    "        return TensorCTScan(torch.stack(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_slice_count = Meta.df_comb.groupby(['SeriesInstanceUID']).agg(['count'])\n",
    "# max(df_slice_count.PatientID.values), min(df_slice_count.PatientID.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "max_seq = 60\n",
    "def pad_batch(x, pad_to=None, value=0):\n",
    "    if isinstance(x, tuple): return tuple([pad_batch(s, pad_to, value) for s in x])\n",
    "    if isinstance(x, dict): return {k:pad_batch(item, pad_to, value) for k,item in x.items()}\n",
    "    bs_pad = pad_to-x.shape[0]\n",
    "    pad = [0]*len(x.shape)*2\n",
    "    pad[-1] = bs_pad\n",
    "    return type(x)(F.pad(x, pad=pad, value=value))\n",
    "\n",
    "# def pad_collate(items, values=[0,-1], pad_to=max_seq):\n",
    "def pad_collate(items, values=[0,-1], pad_to=max_seq):\n",
    "#     def get_bs(x): return x[0].shape[0] if hasattr(x[0], 'shape') else get_bs(x[0])\n",
    "#     pad_to = max([get_bs(x) for x in items]) if fixed_pad is None else fixed_pad\n",
    "    pad_to = 60\n",
    "    def pad_row(row, pad_to, vals): return tuple([pad_batch(x,pad_to,v) for x,v in zip(row,vals)])\n",
    "    res = [pad_row(row, pad_to, values) for row in items]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalization stats for position\n",
    "# pos = Meta.df_comb.ImagePositionPatient2.values\n",
    "# pos.min(), pos.max(), pos.mean(), pos.std()\n",
    "# # (pos - pos.min())/pos.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# saving hardcoded positioning so we can normalize the test set the same way\n",
    "pos_min, pos_max, pos_mean, pos_std = (-998.400024, 1794.01276, 167.08153131830622, 244.90964319136026)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TfmSOP:\n",
    "    def __init__(self,df,open_fn,test=False,meta=False):\n",
    "        store_attr(self, 'df,open_fn,test,meta')\n",
    "    \n",
    "    def x(self, sid):\n",
    "        sids = self.df.SOPInstanceUID[sid].values\n",
    "        imgs = self.open_fn(sids)\n",
    "        if self.meta: \n",
    "            pos = self.df.ImagePositionPatient2[sid].values.reshape(-1, 1)\n",
    "            pos = torch.from_numpy(pos).float()\n",
    "            pos_norm = (pos - pos_mean)/pos_std\n",
    "#             return {'ct':imgs, 'pos':pos_norm}\n",
    "            return imgs, pos_norm\n",
    "        return imgs\n",
    "    \n",
    "    def y(self, sid): \n",
    "        sids = self.df.SOPInstanceUID[sid].values\n",
    "        if self.test: return torch.zeros((self.df.loc[sid].shape[0], 6)).float()\n",
    "        vals = self.df.loc[sid,htypes].values\n",
    "        return TensorMultiCategory(tensor(vals)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_3d_dsets(df, open_fn, grps=Meta.grps_stg1, cv_idx=0, tfms=None, column='SeriesInstanceUID', test=False, meta=False):\n",
    "    df_series = df.reset_index().set_index(column).sort_values([column, \"ImagePositionPatient2\"])\n",
    "    sids = df_series.index.unique()\n",
    "    sid2idx = dict(zip(sids, range(len(sids))))\n",
    "    \n",
    "    # multi index is 10x faster\n",
    "    df_series.index = pd.MultiIndex.from_tuples(df_series.index.str.split('|').tolist())\n",
    "    tfm = TfmSOP(df_series, open_fn, test=test, meta=meta)\n",
    "    \n",
    "    if test: \n",
    "        splits=[L.range(sids), L.range(sids)]\n",
    "    else:\n",
    "        s1 = [sid2idx[sid] for sid in group_cv(cv_idx,grps) if sid in sid2idx]\n",
    "        s2 = [sid2idx[sid] for sid in grps[cv_idx] if sid in sid2idx]\n",
    "        splits = (s1, s2)\n",
    "    dsets = Datasets(sids, [[tfm.x]+L(tfms),[tfm.y]], splits=splits)\n",
    "    return dsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #export\n",
    "# _collate_types = (ndarray, Tensor, typing.Mapping, str)\n",
    "# def test_collate(t):\n",
    "#     b = t[0]\n",
    "#     print('kdfjslfjlsdfk', [type(z) for z in t])\n",
    "    \n",
    "# #     print(t)\n",
    "# #     pdb.set_trace()\n",
    "#     if isinstance(b, tuple): \n",
    "# #         print('sdfds', type(t), type(b))\n",
    "#         return [test_collate(s) for s in zip(*t)]\n",
    "#     if isinstance(b, _collate_types): \n",
    "#         print('ctype', type(t), type(b))\n",
    "# #         print('dsfjsdf', [type(x)(default_collate(x)) for x in t])\n",
    "#         return type(b)(default_collate(t))\n",
    "# #     print('else', type(t))\n",
    "# #     return type(t)(default_collate(t))\n",
    "        \n",
    "# #     return (default_collate(t) if isinstance(b, _collate_types)\n",
    "# #             else type(t[0])([fa_collate(s) for s in zip(*t)]) if isinstance(b, Sequence)\n",
    "# #             else default_collate(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dsets = get_3d_dsets(Meta.df_comb1, open_fn=OpenCTs(path_jpg), \n",
    "#                      grps=Meta.grps_stg1, test=True, meta=True)\n",
    "# test_collate([dsets[0], dsets[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_dls(dsets, bs, batch_tfms, num_workers=8):\n",
    "    before_batch = [pad_collate] if bs != 1 else []\n",
    "    dls = DataLoaders(\n",
    "        TfmdDL(dsets.train, bs=bs, before_batch=before_batch, after_batch=batch_tfms, num_workers=num_workers, shuffle=True),\n",
    "        TfmdDL(dsets.valid, bs=bs, before_batch=before_batch, after_batch=batch_tfms, num_workers=num_workers)\n",
    "    )\n",
    "    dls.device = default_device()\n",
    "    dls.c = 6\n",
    "    return dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_3d_dls(df, path=path_jpg256, bs=1, num_workers=8, tfms=None, **kwargs):\n",
    "    dsets = get_3d_dsets(df, open_fn=OpenCTs(path), **kwargs)\n",
    "\n",
    "    nrm = Normalize.from_stats(mean,std)\n",
    "    batch_tfms = L(IntToFloatTensor(), nrm, *L(tfms))\n",
    "    \n",
    "    return get_dls(dsets, bs, batch_tfms, num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 166 ms, sys: 48.7 ms, total: 215 ms\n",
      "Wall time: 215 ms\n"
     ]
    }
   ],
   "source": [
    "dls = get_3d_dls(Meta.df_comb, path=path_jpg256, bs=2)\n",
    "%time xb,yb = dls.valid.one_batch();\n",
    "# # Wall time: 4.69 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Tfm5D(Transform):\n",
    "    order = 0\n",
    "    def encodes(self, o:TensorImage): return o.view(-1, *o.shape[-3:])\n",
    "class Tfm6D(Transform):\n",
    "    order = 200\n",
    "    def encodes(self, o:TensorImage): return o.view(-1, max_seq, *o.shape[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PipeMeta(Pipeline):\n",
    "    def __call__(self, o): \n",
    "#         if isinstance(o, tuple): return [super(PipeMeta, self).__call__(x) for x in o]\n",
    "        if isinstance(o, tuple): \n",
    "            return super().__call__(TensorCTScan(o[0])), o[1]\n",
    "        return super().__call__(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaTfm(Transform):\n",
    "    def __init__(self, tfms):\n",
    "        super().__init__()\n",
    "        self.pipe = Pipeline(tfms)\n",
    "    def encodes(self, o): \n",
    "        return [self.pipe(x) for x in o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_3d_dls_aug(df, sz=None, path=path_jpg256, bs=1, num_workers=8, grps=Meta.grps_stg1, test=False, meta=False):\n",
    "    dsets = get_3d_dsets(df, open_fn=OpenCTs(path), grps=grps, test=test, meta=meta)\n",
    "    \n",
    "    tfms = [Tfm5D(), IntToFloatTensor(), Tfm6D()]+aug_transforms()\n",
    "    if sz is not None: tfms = tfms+[RandomResizedCropGPU(sz, min_scale=0.7, ratio=(1.,1.), valid_scale=0.9)]\n",
    "\n",
    "    nrm = Normalize.from_stats(mean,std)\n",
    "    batch_tfms = tfms+L(nrm)\n",
    "    \n",
    "    if meta: return get_dls(dsets, bs, [PipeMeta(batch_tfms)], num_workers)\n",
    "    return get_dls(dsets, bs, batch_tfms, num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "??Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broadcast_vec(0,3,mean)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_3d_dls_album(df, sz=None, path=path_jpg256, bs=1, num_workers=8, grps=Meta.grps_stg1, test=False, meta=False):\n",
    "    \n",
    "    nrm = Normalize.from_stats(mean,std,cuda=False,dim=0,ndim=3)\n",
    "    ab_tfms = [ABTfms((sz,sz)), image2tensor, IntToFloatTensor(), nrm]\n",
    "    dsets = get_3d_dsets(df, open_fn=OpenCTs(path, get_cv2_fn, tfms=ab_tfms), grps=grps, test=test, meta=meta)\n",
    "#     batch_tfms = [nrm]\n",
    "    batch_tfms=None\n",
    "    if meta: return get_dls(dsets, bs, batch_tfms, num_workers)\n",
    "    return get_dls(dsets, bs, batch_tfms, num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = get_3d_dls_album(Meta.df_comb, sz=128, bs=2, grps=Meta.grps_stg1, meta=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 60, 3, 128, 128])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = get_3d_dls_aug(Meta.df_comb, sz=128, bs=2, grps=Meta.grps_stg1, meta=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 190 ms, sys: 592 ms, total: 782 ms\n",
      "Wall time: 4.12 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 60, 3, 384, 384])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls = get_3d_dls_aug(Meta.df_tst, sz=384, path=path_tst_jpg, bs=4, test=True, meta=True)\n",
    "%time xb,yb = next(iter(dls.valid)); xb[0].shape\n",
    "# Wall time: 14.2 s - without Tfm5D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Wrap():\n",
    "    def __init__(self, tfm, tfm_all=True): self.tfm = tfm\n",
    "    def __getattr__(self, x): return getattr(self.tfm, x)\n",
    "    def __call__(self, *args, **kwargs): return self.encodes(*args, **kwargs)\n",
    "    def encodes(self, x:TensorImage): return self.reshape(x, self.tfm)\n",
    "    def decodes(self, x:TensorImage): return self.reshape(x, self.tfm.decodes)\n",
    "    \n",
    "    def reshape(self, x, func):\n",
    "        if len(x.shape) != 5: return x\n",
    "        bs,ts,ch,w,h = x.shape\n",
    "        x = x.reshape(-1,ch,w,h)\n",
    "        out = func(x)\n",
    "        return out.reshape(bs,ts, *out.shape[-3:])\n",
    "        \n",
    "\n",
    "# wrapped_tfms = [Wrap(tfm) for tfm in aug_transforms()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dsets = get_3d_dsets(Meta.df_any, open_fn=OpenCTs(path_jpg256))\n",
    "# x,y = dsets[0]\n",
    "# x.shape, y.shape\n",
    "\n",
    "# dls = get_3d_dls(df_any, bs=10)\n",
    "# x,y = dls.one_batch()\n",
    "# x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_np_fn(p):\n",
    "    def _f(fn): return torch.from_numpy(np.load(str(p/f'{fn}.npy')))\n",
    "    return _f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_3d_dls_feat(df, path=path_feat_384avg, bs=1, num_workers=8, test=False, meta=False):\n",
    "    dsets = get_3d_dsets(df, open_fn=OpenCTs(path, get_np_fn), test=test, meta=meta)\n",
    "    return get_dls(dsets, bs, [], num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls_feat = get_3d_dls_feat(Meta.df_comb, bs=10, meta=True)\n",
    "xb,yb = dls_feat.one_batch()\n",
    "# xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6698],\n",
       "         [-0.6538],\n",
       "         [-0.6379],\n",
       "         [-0.6220],\n",
       "         [-0.6061],\n",
       "         [-0.5901],\n",
       "         [-0.5742],\n",
       "         [-0.5583],\n",
       "         [-0.5423],\n",
       "         [-0.5264],\n",
       "         [-0.5105],\n",
       "         [-0.4946],\n",
       "         [-0.4738],\n",
       "         [-0.4525],\n",
       "         [-0.4313],\n",
       "         [-0.4101],\n",
       "         [-0.3888],\n",
       "         [-0.3676],\n",
       "         [-0.3464],\n",
       "         [-0.3251],\n",
       "         [-0.3039],\n",
       "         [-0.2826],\n",
       "         [-0.2614],\n",
       "         [-0.2402],\n",
       "         [-0.2189],\n",
       "         [-0.1977],\n",
       "         [-0.1765],\n",
       "         [-0.1552],\n",
       "         [-0.1340],\n",
       "         [-0.1127],\n",
       "         [-0.0915],\n",
       "         [-0.0703],\n",
       "         [-0.0490],\n",
       "         [-0.0278],\n",
       "         [-0.0066],\n",
       "         [ 0.0147],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000]],\n",
       "\n",
       "        [[-0.6744],\n",
       "         [-0.6528],\n",
       "         [-0.6311],\n",
       "         [-0.6095],\n",
       "         [-0.5878],\n",
       "         [-0.5661],\n",
       "         [-0.5445],\n",
       "         [-0.5228],\n",
       "         [-0.5012],\n",
       "         [-0.4795],\n",
       "         [-0.4578],\n",
       "         [-0.4362],\n",
       "         [-0.4145],\n",
       "         [-0.3929],\n",
       "         [-0.3712],\n",
       "         [-0.3495],\n",
       "         [-0.3279],\n",
       "         [-0.3062],\n",
       "         [-0.2845],\n",
       "         [-0.2629],\n",
       "         [-0.2412],\n",
       "         [-0.2196],\n",
       "         [-0.1979],\n",
       "         [-0.1762],\n",
       "         [-0.1546],\n",
       "         [-0.1329],\n",
       "         [-0.1113],\n",
       "         [-0.0896],\n",
       "         [-0.0679],\n",
       "         [-0.0463],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000]],\n",
       "\n",
       "        [[-0.6467],\n",
       "         [-0.6297],\n",
       "         [-0.6127],\n",
       "         [-0.5956],\n",
       "         [-0.5786],\n",
       "         [-0.5616],\n",
       "         [-0.5445],\n",
       "         [-0.5275],\n",
       "         [-0.5104],\n",
       "         [-0.4934],\n",
       "         [-0.4764],\n",
       "         [-0.4593],\n",
       "         [-0.4423],\n",
       "         [-0.4253],\n",
       "         [-0.4082],\n",
       "         [-0.3912],\n",
       "         [-0.3741],\n",
       "         [-0.3571],\n",
       "         [-0.3401],\n",
       "         [-0.3230],\n",
       "         [-0.3027],\n",
       "         [-0.2800],\n",
       "         [-0.2573],\n",
       "         [-0.2346],\n",
       "         [-0.2119],\n",
       "         [-0.1892],\n",
       "         [-0.1665],\n",
       "         [-0.1437],\n",
       "         [-0.1210],\n",
       "         [-0.0983],\n",
       "         [-0.0756],\n",
       "         [-0.0529],\n",
       "         [-0.0302],\n",
       "         [-0.0075],\n",
       "         [ 0.0152],\n",
       "         [ 0.0380],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000]],\n",
       "\n",
       "        [[-0.3690],\n",
       "         [-0.3486],\n",
       "         [-0.3282],\n",
       "         [-0.3078],\n",
       "         [-0.2874],\n",
       "         [-0.2670],\n",
       "         [-0.2465],\n",
       "         [-0.2261],\n",
       "         [-0.2057],\n",
       "         [-0.1853],\n",
       "         [-0.1649],\n",
       "         [-0.1445],\n",
       "         [-0.1241],\n",
       "         [-0.1036],\n",
       "         [-0.0832],\n",
       "         [-0.0628],\n",
       "         [-0.0424],\n",
       "         [-0.0220],\n",
       "         [-0.0016],\n",
       "         [ 0.0189],\n",
       "         [ 0.0393],\n",
       "         [ 0.0597],\n",
       "         [ 0.0801],\n",
       "         [ 0.1005],\n",
       "         [ 0.1209],\n",
       "         [ 0.1414],\n",
       "         [ 0.1618],\n",
       "         [ 0.1822],\n",
       "         [ 0.2026],\n",
       "         [ 0.2230],\n",
       "         [ 0.2434],\n",
       "         [ 0.2638],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000]],\n",
       "\n",
       "        [[-0.6924],\n",
       "         [-0.6720],\n",
       "         [-0.6516],\n",
       "         [-0.6312],\n",
       "         [-0.6108],\n",
       "         [-0.5903],\n",
       "         [-0.5699],\n",
       "         [-0.5495],\n",
       "         [-0.5291],\n",
       "         [-0.5087],\n",
       "         [-0.4883],\n",
       "         [-0.4679],\n",
       "         [-0.4474],\n",
       "         [-0.4270],\n",
       "         [-0.4066],\n",
       "         [-0.3862],\n",
       "         [-0.3658],\n",
       "         [-0.3454],\n",
       "         [-0.3249],\n",
       "         [-0.3045],\n",
       "         [-0.2841],\n",
       "         [-0.2637],\n",
       "         [-0.2433],\n",
       "         [-0.2229],\n",
       "         [-0.2024],\n",
       "         [-0.1820],\n",
       "         [-0.1616],\n",
       "         [-0.1412],\n",
       "         [-0.1208],\n",
       "         [-0.1004],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000]],\n",
       "\n",
       "        [[-0.4515],\n",
       "         [-0.4311],\n",
       "         [-0.4107],\n",
       "         [-0.3903],\n",
       "         [-0.3699],\n",
       "         [-0.3494],\n",
       "         [-0.3290],\n",
       "         [-0.3086],\n",
       "         [-0.2882],\n",
       "         [-0.2678],\n",
       "         [-0.2474],\n",
       "         [-0.2269],\n",
       "         [-0.2065],\n",
       "         [-0.1861],\n",
       "         [-0.1657],\n",
       "         [-0.1453],\n",
       "         [-0.1249],\n",
       "         [-0.1045],\n",
       "         [-0.0840],\n",
       "         [-0.0636],\n",
       "         [-0.0432],\n",
       "         [-0.0228],\n",
       "         [-0.0024],\n",
       "         [ 0.0180],\n",
       "         [ 0.0385],\n",
       "         [ 0.0589],\n",
       "         [ 0.0793],\n",
       "         [ 0.0997],\n",
       "         [ 0.1201],\n",
       "         [ 0.1405],\n",
       "         [ 0.1610],\n",
       "         [ 0.1814],\n",
       "         [ 0.2018],\n",
       "         [ 0.2222],\n",
       "         [ 0.2426],\n",
       "         [ 0.2630],\n",
       "         [ 0.2834],\n",
       "         [ 0.3039],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000]],\n",
       "\n",
       "        [[-0.3150],\n",
       "         [-0.2936],\n",
       "         [-0.2725],\n",
       "         [-0.2511],\n",
       "         [-0.2300],\n",
       "         [-0.2087],\n",
       "         [-0.1876],\n",
       "         [-0.1662],\n",
       "         [-0.1451],\n",
       "         [-0.1238],\n",
       "         [-0.1026],\n",
       "         [-0.0813],\n",
       "         [-0.0602],\n",
       "         [-0.0388],\n",
       "         [-0.0177],\n",
       "         [ 0.0036],\n",
       "         [ 0.0248],\n",
       "         [ 0.0461],\n",
       "         [ 0.0672],\n",
       "         [ 0.0886],\n",
       "         [ 0.1097],\n",
       "         [ 0.1310],\n",
       "         [ 0.1521],\n",
       "         [ 0.1735],\n",
       "         [ 0.1946],\n",
       "         [ 0.2160],\n",
       "         [ 0.2371],\n",
       "         [ 0.2584],\n",
       "         [ 0.2795],\n",
       "         [ 0.3009],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000]],\n",
       "\n",
       "        [[-0.3415],\n",
       "         [-0.3202],\n",
       "         [-0.2990],\n",
       "         [-0.2777],\n",
       "         [-0.2566],\n",
       "         [-0.2353],\n",
       "         [-0.2141],\n",
       "         [-0.1928],\n",
       "         [-0.1716],\n",
       "         [-0.1503],\n",
       "         [-0.1292],\n",
       "         [-0.1079],\n",
       "         [-0.0867],\n",
       "         [-0.0654],\n",
       "         [-0.0442],\n",
       "         [-0.0230],\n",
       "         [-0.0018],\n",
       "         [ 0.0195],\n",
       "         [ 0.0407],\n",
       "         [ 0.0620],\n",
       "         [ 0.0831],\n",
       "         [ 0.1044],\n",
       "         [ 0.1256],\n",
       "         [ 0.1469],\n",
       "         [ 0.1681],\n",
       "         [ 0.1894],\n",
       "         [ 0.2105],\n",
       "         [ 0.2318],\n",
       "         [ 0.2530],\n",
       "         [ 0.2743],\n",
       "         [ 0.2955],\n",
       "         [ 0.3168],\n",
       "         [ 0.3379],\n",
       "         [ 0.3592],\n",
       "         [ 0.3804],\n",
       "         [ 0.4017],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000]],\n",
       "\n",
       "        [[-0.8813],\n",
       "         [-0.8609],\n",
       "         [-0.8404],\n",
       "         [-0.8200],\n",
       "         [-0.7996],\n",
       "         [-0.7792],\n",
       "         [-0.7588],\n",
       "         [-0.7384],\n",
       "         [-0.7179],\n",
       "         [-0.6975],\n",
       "         [-0.6771],\n",
       "         [-0.6567],\n",
       "         [-0.6363],\n",
       "         [-0.6159],\n",
       "         [-0.5955],\n",
       "         [-0.5750],\n",
       "         [-0.5546],\n",
       "         [-0.5342],\n",
       "         [-0.5138],\n",
       "         [-0.4934],\n",
       "         [-0.4730],\n",
       "         [-0.4525],\n",
       "         [-0.4321],\n",
       "         [-0.4117],\n",
       "         [-0.3913],\n",
       "         [-0.3709],\n",
       "         [-0.3505],\n",
       "         [-0.3300],\n",
       "         [-0.3096],\n",
       "         [-0.2892],\n",
       "         [-0.2688],\n",
       "         [-0.2484],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000]],\n",
       "\n",
       "        [[-0.5014],\n",
       "         [-0.4900],\n",
       "         [-0.4786],\n",
       "         [-0.4673],\n",
       "         [-0.4559],\n",
       "         [-0.4446],\n",
       "         [-0.4332],\n",
       "         [-0.4218],\n",
       "         [-0.4105],\n",
       "         [-0.3991],\n",
       "         [-0.3878],\n",
       "         [-0.3764],\n",
       "         [-0.3651],\n",
       "         [-0.3537],\n",
       "         [-0.3423],\n",
       "         [-0.3310],\n",
       "         [-0.3207],\n",
       "         [-0.2980],\n",
       "         [-0.2752],\n",
       "         [-0.2525],\n",
       "         [-0.2298],\n",
       "         [-0.2071],\n",
       "         [-0.1844],\n",
       "         [-0.1617],\n",
       "         [-0.1390],\n",
       "         [-0.1162],\n",
       "         [-0.0935],\n",
       "         [-0.0708],\n",
       "         [-0.0481],\n",
       "         [-0.0254],\n",
       "         [-0.0027],\n",
       "         [ 0.0200],\n",
       "         [ 0.0428],\n",
       "         [ 0.0655],\n",
       "         [ 0.0882],\n",
       "         [ 0.1109],\n",
       "         [ 0.1336],\n",
       "         [ 0.1563],\n",
       "         [ 0.1790],\n",
       "         [ 0.2018],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000]]], device='cuda:0')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ReshapeBodyHook():\n",
    "    def __init__(self, body):\n",
    "        super().__init__()\n",
    "        self.pre_reg = body.register_forward_pre_hook(self.pre_hook)\n",
    "        self.reg = body.register_forward_hook(self.forward_hook)\n",
    "        self.shape = None\n",
    "    \n",
    "    def deregister(self):\n",
    "        self.reg.remove()\n",
    "        self.pre_reg.remove()\n",
    "        \n",
    "    def pre_hook(self, module, input):\n",
    "        x = input[0]\n",
    "        self.shape = x.shape\n",
    "        return (x.view(-1, *x.shape[2:]),)\n",
    "    \n",
    "    def forward_hook(self, module, input, x):\n",
    "        return x.view(*self.shape[:2], *x.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def conv3(ni,nf,stride=1):\n",
    "    return ConvLayer(ni, nf, (5,3,3), stride=(1,stride,stride), ndim=3, padding=(2,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Batchify(Module):\n",
    "    def forward(self, x): return x.transpose(1,2)\n",
    "\n",
    "class DeBatchify(Module):\n",
    "    def forward(self, x):\n",
    "        x_t = x.transpose(1,2)\n",
    "        x_c = x_t.contiguous().view(-1, *x_t.shape[2:])\n",
    "        return x_c\n",
    "\n",
    "def get_3d_head(concat_pool=True):\n",
    "    pool, feat = (AdaptiveConcatPool2d(1), 64*2) if concat_pool else (nn.AdaptiveAvgPool2d(1), 64)\n",
    "    m = nn.Sequential(Batchify(),\n",
    "        conv3(512,256,2), # 8\n",
    "        conv3(256,128,2), # 4\n",
    "        conv3(128, 64,2), # 2\n",
    "        DeBatchify(), pool, Flatten(), nn.Linear(feat,6))\n",
    "    init_cnn(m)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ignore Padding in Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DePadLoss(Callback):\n",
    "    def __init__(self, pad_idx=-1): \n",
    "        super().__init__()\n",
    "        store_attr(self, 'pad_idx')\n",
    "\n",
    "    def after_pred(self):\n",
    "        learn = self.learn\n",
    "        targ = learn.yb[0].view(-1, *learn.yb[0].shape[2:])\n",
    "        if targ.shape[0] != self.pred.shape[0]:\n",
    "            pred = learn.pred.view(-1, *learn.pred.shape[2:])\n",
    "        else: pred = learn.pred\n",
    "        \n",
    "        mask = targ[:,-1] != self.pad_idx\n",
    "        \n",
    "        learn.pred = pred[mask]\n",
    "        learn.yb = (targ[mask],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Features - By Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls_feat = get_3d_dls_feat(Meta.df_any, bs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = get_3d_head()\n",
    "learn = get_learner(dls_feat, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai2.learner.Learner at 0x7fd0316ad6d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.add_cb(DePadLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit(learn, 1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on Slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = get_3d_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = get_3d_dls_aug(Meta.df_any, bs=10)\n",
    "config=dict(custom_head=m, init=None)\n",
    "learn = get_learner(dls, resnet18, get_loss(), config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.model[0] = ReshapeCNNBody(learn.model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "hook = ReshapeBodyHook(learn.model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai2.learner.Learner at 0x7f5be0f68710>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.add_cb(DePadLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit(learn, 1, 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_metadata.ipynb.\n",
      "Converted 01_preprocess.ipynb.\n",
      "Converted 01_preprocess_mean_std.ipynb.\n",
      "Converted 02_train.ipynb.\n",
      "Converted 02_train_01_save_features.ipynb.\n",
      "Converted 03_train3d.ipynb.\n",
      "Converted 04_trainfull3d_deprecated.ipynb.\n",
      "Converted 04_trainfull3d_labels.ipynb.\n",
      "Converted 05_train_adjacent.ipynb.\n",
      "Converted 06_seutao_features.ipynb.\n",
      "Converted Tabular_02_FeatureImportance.ipynb.\n",
      "Converted Untitled.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
