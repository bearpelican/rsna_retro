{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp train3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading imports\n",
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/ashaw/.kaggle/kaggle.json'\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "from rsna_retro.imports import *\n",
    "from rsna_retro.metadata import *\n",
    "from rsna_retro.preprocess import *\n",
    "from rsna_retro.train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class OpenCTs:\n",
    "    def __init__(self, path): \n",
    "        self.fn = get_pil_fn(path)\n",
    "        self.tt = ToTensor()\n",
    "    def __call__(self, item):\n",
    "        if isinstance(item, (str, Path)): return self.fn(item)\n",
    "        xs = [self.tt(self.fn(x)) for x in item]\n",
    "        return TensorCTScan(torch.stack(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_slice_count = Meta.df_comb.groupby(['SeriesInstanceUID']).agg(['count'])\n",
    "# max(df_slice_count.PatientID.values), min(df_slice_count.PatientID.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "max_seq = 60\n",
    "def pad_batch(x, pad_to=None, value=0):\n",
    "    if isinstance(x, tuple): return tuple([pad_batch(s, pad_to, value) for s in x])\n",
    "    bs_pad = pad_to-x.shape[0]\n",
    "    pad = [0]*len(x.shape)*2\n",
    "    pad[-1] = bs_pad\n",
    "    return F.pad(x, pad=pad, value=value)\n",
    "\n",
    "def pad_collate(items, values=[0,-1], pad_to=max_seq):\n",
    "    def get_bs(x): return x[0].shape[0] if hasattr(x[0], 'shape') else get_bs(x[0])\n",
    "#     pad_to = max([get_bs(x) for x in items]) if fixed_pad is None else fixed_pad\n",
    "    pad_to = 60\n",
    "    def pad_row(row, pad_to, vals): return tuple([pad_batch(x,pad_to,v) for x,v in zip(row,vals)])\n",
    "    return [pad_row(row, pad_to, values) for row in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TfmSOP:\n",
    "    def __init__(self,df,open_fn,test=False):\n",
    "        self.open_fn = open_fn\n",
    "        self.df = df\n",
    "        self.test=test\n",
    "    \n",
    "    def x(self, sid):\n",
    "        sids = self.df.SOPInstanceUID[sid].values\n",
    "        return self.open_fn(sids)\n",
    "    \n",
    "    def y(self, sid): \n",
    "        sids = self.df.SOPInstanceUID[sid].values\n",
    "        if self.test: return torch.zeros((self.df.loc[sid].shape[0], 6)).float()\n",
    "        vals = self.df.loc[sid,htypes].values\n",
    "        return TensorMultiCategory(tensor(vals)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_3d_dsets(df, open_fn, grps=Meta.grps_stg1, cv_idx=0, tfms=None, column='SeriesInstanceUID', test=False):\n",
    "    df_series = df.reset_index().set_index(column).sort_values([column, \"ImagePositionPatient2\"])\n",
    "    sids = df_series.index.unique()\n",
    "    sid2idx = dict(zip(sids, range(len(sids))))\n",
    "    \n",
    "    # multi index is 10x faster\n",
    "    df_series.index = pd.MultiIndex.from_tuples(df_series.index.str.split('|').tolist())\n",
    "    tfm = TfmSOP(df_series, open_fn, test=test)\n",
    "    \n",
    "    if test: \n",
    "        splits=[L.range(sids), L.range(sids)]\n",
    "    else:\n",
    "        s1 = [sid2idx[sid] for sid in group_cv(cv_idx,grps) if sid in sid2idx]\n",
    "        s2 = [sid2idx[sid] for sid in grps[cv_idx] if sid in sid2idx]\n",
    "        splits = (s1, s2)\n",
    "    dsets = Datasets(sids, [[tfm.x]+L(tfms),[tfm.y]], splits=splits)\n",
    "    return dsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_dls(dsets, bs, batch_tfms, num_workers=8):\n",
    "    before_batch = [pad_collate] if bs != 1 else []\n",
    "    dls = DataLoaders(\n",
    "        TfmdDL(dsets.train, bs=bs, before_batch=before_batch, after_batch=batch_tfms, num_workers=num_workers, shuffle=True),\n",
    "        TfmdDL(dsets.valid, bs=bs, before_batch=before_batch, after_batch=batch_tfms, num_workers=num_workers)\n",
    "    )\n",
    "    dls.device = default_device()\n",
    "    dls.c = 6\n",
    "    return dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_3d_dls(df, path=path_jpg256, bs=1, num_workers=8, tfms=None):\n",
    "    dsets = get_3d_dsets(df, open_fn=OpenCTs(path))\n",
    "\n",
    "    nrm = Normalize.from_stats(mean,std)\n",
    "    batch_tfms = L(nrm, IntToFloatTensor(), *L(tfms))\n",
    "    \n",
    "    return get_dls(dsets, bs, batch_tfms, num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = get_3d_dsets(Meta.df_tst, open_fn=OpenCTs(path_tst_jpg), tfms=[IntToFloatTensor()], grps=None, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dls = get_3d_dls(Meta.df_comb, path=path_jpg, bs=4)\n",
    "# %time xb,yb = next(iter(dls.valid)); xb.shape, yb.shape\n",
    "# # Wall time: 4.69 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Tfm5D(Transform):\n",
    "    order = 0\n",
    "    def encodes(self, o:TensorImage): return o.view(-1, *o.shape[-3:])\n",
    "class Tfm6D(Transform):\n",
    "    order = 200\n",
    "    def encodes(self, o:TensorImage): return o.view(-1, max_seq, *o.shape[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_3d_dls_aug(df, sz=None, path=path_jpg256, bs=1, num_workers=8, grps=Meta.grps_stg1, test=False):\n",
    "    dsets = get_3d_dsets(df, open_fn=OpenCTs(path), grps=grps, test=test)\n",
    "    \n",
    "    tfms = [Tfm5D(), IntToFloatTensor(), Tfm6D()]+aug_transforms()\n",
    "    if sz is not None: tfms = tfms+[RandomResizedCropGPU(sz, min_scale=0.7, ratio=(1.,1.), valid_scale=0.9)]\n",
    "\n",
    "    nrm = Normalize.from_stats(mean,std)\n",
    "    batch_tfms = tfms+L(nrm)\n",
    "    return get_dls(dsets, bs, batch_tfms, num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 350 ms, sys: 551 ms, total: 902 ms\n",
      "Wall time: 3.28 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 60, 3, 384, 384])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls = get_3d_dls_aug(Meta.df_tst, sz=384, path=path_tst_jpg, bs=4, test=True)\n",
    "%time xb,yb = next(iter(dls.valid)); xb.shape\n",
    "# Wall time: 14.2 s - without Tfm5D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Wrap():\n",
    "    def __init__(self, tfm, tfm_all=True): self.tfm = tfm\n",
    "    def __getattr__(self, x): return getattr(self.tfm, x)\n",
    "    def __call__(self, *args, **kwargs): return self.encodes(*args, **kwargs)\n",
    "    def encodes(self, x:TensorImage): return self.reshape(x, self.tfm)\n",
    "    def decodes(self, x:TensorImage): return self.reshape(x, self.tfm.decodes)\n",
    "    \n",
    "    def reshape(self, x, func):\n",
    "        if len(x.shape) != 5: return x\n",
    "        bs,ts,ch,w,h = x.shape\n",
    "        x = x.reshape(-1,ch,w,h)\n",
    "        out = func(x)\n",
    "        return out.reshape(bs,ts, *out.shape[-3:])\n",
    "        \n",
    "\n",
    "# wrapped_tfms = [Wrap(tfm) for tfm in aug_transforms()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dsets = get_3d_dsets(Meta.df_any, open_fn=OpenCTs(path_jpg256))\n",
    "# x,y = dsets[0]\n",
    "# x.shape, y.shape\n",
    "\n",
    "# dls = get_3d_dls(df_any, bs=10)\n",
    "# x,y = dls.one_batch()\n",
    "# x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_np_fn(p):\n",
    "    def _f(fn): return torch.from_numpy(np.load(str(p/f'{fn}.npy')))\n",
    "    return _f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class OpenFeats:\n",
    "    def __init__(self, path):\n",
    "        self.fn = get_np_fn(path)\n",
    "    def __call__(self, item):\n",
    "        if isinstance(item, (str, Path)): return self.fn(item)\n",
    "        xs = [self.fn(x) for x in item]\n",
    "        return TensorCTScan(torch.stack(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_3d_dls_feat(df, path=path/'features_256', bs=1, num_workers=8):\n",
    "    dsets = get_3d_dsets(df, open_fn=OpenFeats(path))\n",
    "    return get_dls(dsets, bs, [], num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dls_feat = get_3d_dls_feat(df_any, bs=10)\n",
    "# xb,yb = dls_feat.one_batch()\n",
    "# xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ReshapeBodyHook():\n",
    "    def __init__(self, body):\n",
    "        super().__init__()\n",
    "        self.pre_reg = body.register_forward_pre_hook(self.pre_hook)\n",
    "        self.reg = body.register_forward_hook(self.forward_hook)\n",
    "        self.shape = None\n",
    "    \n",
    "    def deregister(self):\n",
    "        self.reg.remove()\n",
    "        self.pre_reg.remove()\n",
    "        \n",
    "    def pre_hook(self, module, input):\n",
    "        x = input[0]\n",
    "        self.shape = x.shape\n",
    "        return (x.view(-1, *x.shape[2:]),)\n",
    "    \n",
    "    def forward_hook(self, module, input, x):\n",
    "        return x.view(*self.shape[:2], *x.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def conv3(ni,nf,stride=1):\n",
    "    return ConvLayer(ni, nf, (5,3,3), stride=(1,stride,stride), ndim=3, padding=(2,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Batchify(Module):\n",
    "    def forward(self, x): return x.transpose(1,2)\n",
    "\n",
    "class DeBatchify(Module):\n",
    "    def forward(self, x):\n",
    "        x_t = x.transpose(1,2)\n",
    "        x_c = x_t.contiguous().view(-1, *x_t.shape[2:])\n",
    "        return x_c\n",
    "\n",
    "def get_3d_head(concat_pool=True):\n",
    "    pool, feat = (AdaptiveConcatPool2d(1), 64*2) if concat_pool else (nn.AdaptiveAvgPool2d(1), 64)\n",
    "    m = nn.Sequential(Batchify(),\n",
    "        conv3(512,256,2), # 8\n",
    "        conv3(256,128,2), # 4\n",
    "        conv3(128, 64,2), # 2\n",
    "        DeBatchify(), pool, Flatten(), nn.Linear(feat,6))\n",
    "    init_cnn(m)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ignore Padding in Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DePadLoss(Callback):\n",
    "    def __init__(self, pad_idx=-1): \n",
    "        super().__init__()\n",
    "        store_attr(self, 'pad_idx')\n",
    "\n",
    "    def after_pred(self):\n",
    "        learn = self.learn\n",
    "        targ = learn.yb[0].view(-1, *learn.yb[0].shape[2:])\n",
    "        if targ.shape[0] != self.pred.shape[0]:\n",
    "            pred = learn.pred.view(-1, *learn.pred.shape[2:])\n",
    "        else: pred = learn.pred\n",
    "        \n",
    "        mask = targ[:,-1] != self.pad_idx\n",
    "        \n",
    "        learn.pred = pred[mask]\n",
    "        learn.yb = (targ[mask],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Features - By Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls_feat = get_3d_dls_feat(Meta.df_any, bs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = get_3d_head()\n",
    "learn = get_learner(dls_feat, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai2.learner.Learner at 0x7fd0316ad6d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.add_cb(DePadLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit(learn, 1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on Slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = get_3d_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = get_3d_dls_aug(Meta.df_any, bs=10)\n",
    "config=dict(custom_head=m, init=None)\n",
    "learn = get_learner(dls, resnet18, get_loss(), config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.model[0] = ReshapeCNNBody(learn.model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "hook = ReshapeBodyHook(learn.model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai2.learner.Learner at 0x7f5be0f68710>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.add_cb(DePadLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit(learn, 1, 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_metadata.ipynb.\n",
      "Converted 01_preprocess.ipynb.\n",
      "Converted 01_preprocess_mean_std.ipynb.\n",
      "Converted 02_train.ipynb.\n",
      "Converted 03_train3d.ipynb.\n",
      "Converted 03_train3d_01_train3d.ipynb.\n",
      "Converted 03_train3d_01b_train_lstm.ipynb.\n",
      "Converted 03_train3d_02_train_3d_head.ipynb.\n",
      "Converted 03_train3d_02_train_lstm_head.ipynb.\n",
      "Converted 03_trainfull3d.ipynb.\n",
      "Converted 04_trainSeq_01_lstm.ipynb.\n",
      "Converted 04_trainSeq_02_transformer.ipynb.\n",
      "Converted 04_trainSeq_03_lstm_seutao.ipynb.\n",
      "Converted 05_train_adjacent.ipynb.\n",
      "Converted 05_train_adjacent_01_5c_windowed.ipynb.\n",
      "Converted 05_train_adjacent_01_5slice.ipynb.\n",
      "Converted 05_train_adjacent_02_3c.ipynb.\n",
      "Converted 05_train_adjacent_02_3c_stg1.ipynb.\n",
      "Converted 06_seutao_features.ipynb.\n",
      "Converted 06_seutao_features_01_simple_lstm_20ep.ipynb.\n",
      "Converted 06_seutao_features_01b_simple_lstm_10ep.ipynb.\n",
      "Converted 06_seutao_features_01c_simple_lstm_meta.ipynb.\n",
      "Converted 06_seutao_features_01d_simple_lstm_meta_full.ipynb.\n",
      "Converted 06_seutao_features_02_2ndPlace.ipynb.\n",
      "Converted 06_seutao_features_03_1stPlace.ipynb.\n",
      "Converted 06_seutao_features_04_Transformer.ipynb.\n",
      "Converted 06_seutao_features_04_Transformer_meta.ipynb.\n",
      "Converted 07_train_3d_lstm.ipynb.\n",
      "Converted Tabular_02_FeatureImportance.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
