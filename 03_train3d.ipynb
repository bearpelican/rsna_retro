{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp train3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading imports\n",
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/ashaw/.kaggle/kaggle.json'\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (train.py, line 51)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/home/ashaw/anaconda3/envs/rsna_retro/lib/python3.7/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3319\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-64e22b1fc645>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from rsna_retro.train import *\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/home/ashaw/kaggle/rsna_retro/rsna_retro/train.py\"\u001b[0;36m, line \u001b[0;32m51\u001b[0m\n\u001b[0;31m    return get_data_gen(L(list(Meta.df_comb`.index)), bs=bs, img_tfm=get_pil_fn(path/img_dir),\u001b[0m\n\u001b[0m                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "from rsna_retro.imports import *\n",
    "from rsna_retro.metadata import *\n",
    "from rsna_retro.preprocess import *\n",
    "from rsna_retro.train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_any = Meta.df_any\n",
    "df_any.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slice_count = df_any.groupby(['SeriesInstanceUID']).agg(['count'])\n",
    "max(df_slice_count.PatientID.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "max_seq_len = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class OpenCTs:\n",
    "    def __init__(self, path): \n",
    "        self.fn = get_pil_fn(path)\n",
    "        self.tt = ToTensor()\n",
    "    def __call__(self, item):\n",
    "        if isinstance(item, (str, Path)): return self.fn(item)\n",
    "        xs = [self.tt(self.fn(x)) for x in item]\n",
    "        xs\n",
    "        return TensorCTScan(torch.stack(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def pad_batch(x, pad_to=None, value=0):\n",
    "    bs_pad = pad_to-x.shape[0]\n",
    "    pad = [0]*len(x.shape)*2\n",
    "    pad[-1] = bs_pad\n",
    "    return F.pad(x, pad=pad, value=value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad_batch(x, to=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TfmSOP:\n",
    "    def __init__(self,df,open_fn,pad_to=None):\n",
    "        self.open_fn = open_fn\n",
    "        self.df = df\n",
    "        self.pad_to = pad_to\n",
    "    \n",
    "    def x(self, sid):\n",
    "        sids = self.df.SOPInstanceUID[sid].values\n",
    "        x = self.open_fn(sids)\n",
    "        if self.pad_to is None: return x\n",
    "        t = type(x)\n",
    "        return t(pad_batch(x, pad_to=self.pad_to))\n",
    "    \n",
    "    def y(self, sid): \n",
    "        vals = self.df.loc[sid,htypes].values\n",
    "        if self.pad_to is not None: \n",
    "            vals = pad_batch(tensor(vals), pad_to=self.pad_to, value=-1)\n",
    "        return TensorMultiCategory(vals).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_3d_dsrc(df, open_fn, grps=Meta.grps, cv_idx=0, column='SeriesInstanceUID',\n",
    "               pad_to=None):\n",
    "    df_series = df.reset_index().set_index(column).sort_values(\"ImagePositionPatient2\")\n",
    "    tfm = TfmSOP(df_series, open_fn, pad_to)\n",
    "    sids = df_series.index.unique()\n",
    "    \n",
    "    s1 = np.where(np.in1d(sids, group_cv(cv_idx,grps)))[0]\n",
    "    s2 = np.where(np.in1d(sids, grps[cv_idx]))[0]\n",
    "    dsrc = DataSource(sids, [[tfm.x],[tfm.y]], splits=(s1,s2))\n",
    "    return dsrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_3d_dbunch(df, path=path_jpg256, bs=None, num_workers=8):\n",
    "    pad_to = None if bs is None else max_seq_len\n",
    "    dsrc = get_3d_dsrc(df, open_fn=OpenCTs(path), pad_to=pad_to)\n",
    "\n",
    "    nrm = Normalize.from_stats(mean,std)\n",
    "    batch_tfms = L(nrm, Cuda(), IntToFloatTensor())\n",
    "\n",
    "    dbunch = DataBunch(\n",
    "        TfmdDL(dsrc.train, bs=bs, after_batch=batch_tfms, num_workers=num_workers, shuffle=True),\n",
    "        TfmdDL(dsrc.valid, bs=bs, after_batch=batch_tfms, num_workers=num_workers)\n",
    "    )\n",
    "    dbunch.device = default_device()\n",
    "    dbunch.c = 6\n",
    "    return dbunch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60, 3, 256, 256]), torch.Size([60, 6]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc = get_3d_dsrc(df_any, open_fn=OpenCTs(path_jpg256), pad_to=max_seq_len)\n",
    "x,y = dsrc[0]\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbunch = get_3d_dbunch(df_any, bs=10)\n",
    "# x,y = dbunch.one_batch()\n",
    "# x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_np_fn(p):\n",
    "    def _f(fn): return torch.from_numpy(np.load(str(p/f'{fn}.npy')))\n",
    "    return _f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class OpenFeats:\n",
    "    def __init__(self, path):\n",
    "        self.fn = get_np_fn(path)\n",
    "        self.tt = ToTensor()\n",
    "    def __call__(self, item):\n",
    "        if isinstance(item, (str, Path)): return self.fn(item)\n",
    "        xs = [self.tt(self.fn(x)) for x in item]\n",
    "        return TensorCTScan(torch.stack(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_3d_dbunch_feat(df, path=path/'features_256', bs=1, num_workers=8):\n",
    "    pad_to = None if bs == 1 else max_seq_len\n",
    "    dsrc = get_3d_dsrc(df, open_fn=OpenFeats(path), pad_to=pad_to)\n",
    "\n",
    "    dbunch = DataBunch(\n",
    "        TfmdDL(dsrc.train, bs=bs, after_batch=[Cuda()], num_workers=num_workers, shuffle=True),\n",
    "        TfmdDL(dsrc.valid, bs=bs, after_batch=[Cuda()], num_workers=num_workers)\n",
    "    )\n",
    "    dbunch.device = default_device()\n",
    "    dbunch.c = 6\n",
    "    return dbunch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbunch_feat = get_3d_dbunch_feat(df_any, bs=10)\n",
    "# xb,yb = dbunch_feat.one_batch()\n",
    "# xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ReshapeBodyHook():\n",
    "    def __init__(self, body):\n",
    "        super().__init__()\n",
    "        body.register_forward_pre_hook(self.pre_hook)\n",
    "        body.register_forward_hook(self.forward_hook)\n",
    "        self.shape = None\n",
    "        \n",
    "    def pre_hook(self, module, input):\n",
    "        x = input[0]\n",
    "        self.shape = x.shape\n",
    "        return (x.view(-1, *x.shape[2:]),)\n",
    "    \n",
    "    def forward_hook(self, module, input, x):\n",
    "        return x.view(*self.shape[:2], *x.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def conv3(ni,nf,stride=1):\n",
    "    return ConvLayer(ni, nf, (5,3,3), stride=(1,stride,stride), ndim=3, padding=(2,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Batchify(Module):\n",
    "    def forward(self, x): return x.transpose(1,2)\n",
    "\n",
    "class DeBatchify(Module):\n",
    "    def forward(self, x):\n",
    "        x_t = x.transpose(1,2)\n",
    "        x_c = x_t.contiguous().view(-1, *x_t.shape[2:])\n",
    "        return x_c\n",
    "\n",
    "def get_3d_head():\n",
    "    m = nn.Sequential(Batchify(),\n",
    "        conv3(512,256,2), # 8\n",
    "        conv3(256,128,2), # 4\n",
    "        conv3(128, 64,2), # 2\n",
    "        DeBatchify(), nn.AdaptiveAvgPool2d(1), Flatten(), nn.Linear(64,6))\n",
    "    init_cnn(m)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ignore Padding in Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DePadLoss(Callback):\n",
    "    def __init__(self, pad_idx=-1): \n",
    "        super().__init__()\n",
    "        store_attr(self, 'pad_idx')\n",
    "\n",
    "    def after_pred(self):\n",
    "        learn = self.learn\n",
    "        targ = learn.yb[0].view(-1, *learn.yb[0].shape[2:])\n",
    "        if targ.shape[0] != self.pred.shape[0]:\n",
    "            pred = learn.pred.view(-1, *learn.pred.shape[2:])\n",
    "        else: pred = learn.pred\n",
    "        \n",
    "        mask = targ[:,-1] != self.pad_idx\n",
    "        \n",
    "        learn.pred = pred[mask]\n",
    "        learn.yb = (targ[mask],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Features - By Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbunch_feat = get_3d_dbunch_feat(df_any, bs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = get_3d_head()\n",
    "learn = get_learner(dbunch_feat, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai2.learner.Learner at 0x7f6cec3bbd90>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.add_cb(DePadLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy_multi</th>\n",
       "      <th>accuracy_any</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.108049</td>\n",
       "      <td>0.104689</td>\n",
       "      <td>0.963100</td>\n",
       "      <td>0.940114</td>\n",
       "      <td>01:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "do_fit(learn, 1, 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on Slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = get_3d_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbunch = get_3d_dbunch(df_any, bs=10)\n",
    "config=dict(custom_head=m, init=None)\n",
    "learn = get_learner(dbunch, resnet18, get_loss(), config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.model[0] = ReshapeCNNBody(learn.model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hook = ReshapeBodyHook(learn.model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai2.learner.Learner at 0x7fdd90635550>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.add_cb(DePadLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit(learn, 1, 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_metadata.ipynb.\n",
      "Converted 01_preprocess.ipynb.\n",
      "Converted 02_train.ipynb.\n",
      "Converted 03_train3d.ipynb.\n",
      "Converted 03_train3d_01_train3d.ipynb.\n",
      "Converted 03_train3d_02_train_head.ipynb.\n",
      "Converted 04_trainSeq_01_lstm.ipynb.\n",
      "Converted 04_trainSeq_02_transformer.ipynb.\n",
      "Converted 05_train_slice.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
